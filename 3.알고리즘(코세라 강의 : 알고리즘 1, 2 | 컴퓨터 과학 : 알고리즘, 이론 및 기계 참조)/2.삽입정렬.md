# 정렬의 필요성

이진 검색이 효과적으로 작동하기 위해서는 데이터가 정렬된 상태여야한다는 것은 이제 알것이다.
정렬은 단순히 특정 알고리즘의 필요에 국한되는 요소가 아니다. 통계와 데이터베이스, 데이터 압축, 생물 정보학, 컴퓨터 그래픽, 과학 컴퓨팅 등에 사용된다.
렬은 여러 분야에서 데이터 처리의 기본이기 때문에, 컴퓨터가 데이터를 효율적으로 처리하기 위해 정렬 작업에 상당한 연산 능력을 소비하고 있다.


## 삽입 정렬

삽입 정렬은 배열의 각 요소를 순서대로 확인하며, 자신의 위치를 찾아 삽입해 나가는 방식이다.
이미 정렬된 부분과 그렇지 않은 부분으로 나누어, 정렬되지 않은 요소를 적절한 위치에 삽입함으로써 점진적으로 정렬 상태를 확정한다.

배열의 첫 번째 요소는 이미 정렬된 것으로 간주하고, 두 번째 요소부터 시작하여 적절한 위치에 삽입해 나간다.
이전 요소와 비교하여 더 작은 경우, 그 위치에 삽입다.


## 예제 코드

``` java
public class Insertion {
  public static void sort(String[] a) {
  int N = a.length;
  for(int i = 1; i < N; i++) {
    for(int j = i; j > 0; j--) {
      if(a[j-1].compareTo(a[j]) > 0) exch(a, j-1, j);
      else break;
    }
  }
  }
  private static void exch(String[] a, int i, int j) {
    String t = a[i]; a[i] = a[j]; a[j] = t;
  }
  public static void main(String[] args) {
    String [] a = StdIn.readAllStrings();
    sort(a);
    for(int i = 0; i < a.length; i++) StdOut.println(a[i]) ;
  }
}
```

요컨데 sort 메서드에서 최초의 인덱스 문자는 정렬이 되었다고 가정하고 반복문의 시작을 인덱스 1로 시작한다.
이후 인덱스 0과 1을 compartTo 메서드로 비교하고 양수가 나오면(즉 인덱스 0의 문자가 1보다 크다면) exch 메서드를 이용해 작은 요소가 앞으로 오게끔 하는 것이다.

거의 정렬된 데이터를 처리할 때나 데이터 량이 적은 경우에는 성능이 나쁘지 않다.

시간 복잡도는 최악과 평균적인 경우 O(N^2)이고 최선의 경우는 O(N)이 나온다.

이는 반대로 이야기하면, **대규모 데이터에는 몹시 비효율적**이다.


실제 강의에서는 4만개의 데이터를 삽입 정렬시에 4초 정도가 걸렸는데, 만약 백만개의 이름을 정렬한다고 가정하면, 무려 4시간이 걸린다.
심지어 이는 오늘날의 컴퓨터가 매우 빨라졌다는 걸 감안해서 이정도인 것이다.


## 향후 방향성

무어의 법칙에 따르면 컴퓨터의 성능은 매 2년마다 두 배로 증가한다고 한다.(물론 이 법칙은 현재는 점점 논파되어가는 분위기지만..) 이 법칙은 컴퓨터의 처리 능력과 메모리 용량이 지속적으로 향상된다는 것을 의미하며, 이러한 발전을 바탕으로 더 큰 규모의 문제를 더 효율적으로 해결할 수 있다는 것이다. 하지만 하드웨어 성능이 향상된다고 해서 모든 소프트웨어 문제를 쉽게 해결할 수 있는 것은 아니다. 알고리즘의 효율성이 함께 뒷받침되지 않으면, 여전히 성능의 한계에 부딪힐 수밖에 없다.

앞서 이야기했듯이, 삽입 정렬과 같은 간단한 정렬 알고리즘은 작은 규모의 데이터나 거의 정렬된 데이터에서는 충분히 효과적일 수 있다. 하지만 삽입 정렬의 시간 복잡도는 **O(N^2)** 로, 데이터의 양이 조금만 증가해도 정렬 시간이 기하급수적으로 늘어나게 된다. 문제의 크기가 두 배로 증가할 때 실행 시간은 네 배로 늘어나는 형태로, 이는 **확장성(scalability)** 이 떨어지는 것을 의미한다. 이러한 알고리즘은 데이터가 방대해질수록 그 한계가 명확해지며, 하드웨어 성능이 두 배로 빨라지더라도 문제 해결에 필요한 시간은 여전히 비효율적일 수밖에 없다.

따라서 우리는 더 효율적이고 확장 가능한 정렬 알고리즘을 필요로 한다. 예를 들어, **병합 정렬(Merge Sort)** 이나 **퀵 정렬(Quick Sort)**과 같은 알고리즘은 **O(N log N)** 의 시간 복잡도를 가지며, 대규모 데이터에서도 비교적 효율적으로 동작할 수 있다. 이러한 알고리즘들은 데이터의 양이 두 배로 증가해도 실행 시간이 네 배로 늘어나는 것이 아니라, 더 완만하게 증가하기 때문에 확장성 면에서 큰 이점을 제공한다. 즉, 무어의 법칙에 따른 하드웨어 성능의 향상과 함께 이러한 확장 가능한 알고리즘을 적용한다면, 더 큰 문제를 효율적으로 해결할 수 있는 가능성이 열린다.

결론적으로, 현대의 컴퓨팅 환경에서 중요한 것은 하드웨어의 성능 향상에 걸맞는 효율적인 알고리즘을 개발하고 적용하는 것이다. 무어의 법칙에 보조를 맞추기 위해서는 삽입 정렬과 같은 2차 시간 복잡도를 가진 알고리즘에서 벗어나 N log N 시간 복잡도를 가진 알고리즘으로의 전환이 필요하다. 이를 통해 더 큰 문제를 다룰 때도 성능 저하 없이 해결할 수 있으며, 이는 현대 컴퓨팅에서 요구되는 확장성을 달성하는 데 중요한 역할을 할 것이다.
